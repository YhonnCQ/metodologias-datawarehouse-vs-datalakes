\documentclass[twoside,twocolumn]{article}

\usepackage{blindtext} 
\usepackage{graphicx}
\usepackage[sc]{mathpazo} 
\usepackage[T1]{fontenc} 
\linespread{1.05} 
\usepackage{microtype} 


\usepackage[spanish,english]{babel} 


\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} 
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} 
\usepackage{booktabs} 


\usepackage{lettrine} 


\usepackage{enumitem} 
\setlist[itemize]{noitemsep} 


\usepackage{abstract} 
\renewcommand{\abstractnamefont}{\normalfont\bfseries} 
\renewcommand{\abstracttextfont}{\normalfont\small\itshape} 


\usepackage{titlesec} 
\renewcommand\thesection{\Roman{section}} % 
\renewcommand\thesubsection{\roman{subsection}} 
\titleformat{\section}[block]{\large\scshape\centering}{\thesection.}{1em}{} 
\titleformat{\subsection}[block]{\large}{\thesubsection.}{1em}{} 


\usepackage{fancyhdr} 
\pagestyle{fancy} 
\fancyhead{} 
\fancyfoot{} 
\fancyhead[C]{Lorem Ipsum \today} 
\fancyfoot[RO,LE]{\thepage} 


\usepackage{titling} 

%----------------------------------------------------------------------------------------
%	TILULOS
%----------------------------------------------------------------------------------------


\setlength{\droptitle}{-4\baselineskip} 

\pretitle{\begin{center}\Huge\bfseries} 
\posttitle{\end{center}} 
\title{Comparison of Datawarehouse elaboration methodologies vs. Datalake elaboration methodologies} 
\author{
	Valdivia Guzman, Alejandra Maria\\
	\and
	Pazos Alarcón, Christian Joshua\\
	\and
	Farfan Colque, Mathius Omar\\
	\and
	Condori Quispe, Yhónn Joel\\
}
\date{\today} 
\renewcommand{\maketitlehookd}{
\selectlanguage{spanish} 
\begin{abstract}
\noindent 
Los lagos de datos y los almacenes de datos son dos formas estándar en que las empresas almacenan y
administran sus datos. La industria y las necesidades de una empresa influyen en qué opción de almacenamiento
funciona mejor. Comprender sus características únicas puede ayudar a las empresas a tomar decisiones informadas
sobre la gestión de datos. En este artículo, examinamos los lagos de datos frente a los almacenes de datos, destacamos
cinco diferencias y discutimos cuándo usar ambas opciones de almacenamiento.
\end{abstract}
\selectlanguage{english} 
\begin{abstract}
\noindent 
Data lakes and data warehouses are two standard ways that companies store and manage their data. A company's industry
and needs influence which storage option works best. Understanding their unique features can help businesses make informed
decisions about data management. In this article, we examine data lakes vs. data warehouses, highlight five differences and
discuss when to use both storage options.
\end{abstract}
}

%----------------------------------------------------------------------------------------

\begin{document}

% Print the title
\maketitle

%----------------------------------------------------------------------------------------
%	Introduction
%----------------------------------------------------------------------------------------

\section{Introduction}

\lettrine[nindent=0em,lines=3]{D}ata lakes and data warehouses are both widely used for storing big data, but they are not
interchangeable terms. A data lake is a vast pool of raw data, the purpose for which is not yet defined. A data warehouse is
a repository for structured, filtered data that has already been processed for a specific purpose. There is even an emerging
data management architecture trend of the data lakehouse, which combines the flexibility of a data lake with the data
management capabilities of a data warehouse.
The two types of data storage are often confused, but are much more different than they are alike. In fact, the only real
similarity between them is their high-level purpose of storing data.
The distinction is important because they serve different purposes and require different sets of eyes to be properly
optimized. While a data lake works for one company, a data warehouse will be a better fit for another.


%----------------------------------------------------------------------------------------
%	State of Art
%----------------------------------------------------------------------------------------

\section{State of Art}

\subsection{Datawarehouse}

Kimball's methodology, called Dimensional Modeling, is based on what is called the Business Dimensional
Lifecycle. This methodology is considered one of the favorite techniques when building a Data Warehouse\cite{mdawa}.

In the Dimensional Model, models of tables and relationships are constituted with the purpose of optimizing
decision making, based on queries made in a relational database that are linked to the measurement or a
set of measurements of the results of the business processes\cite{mdawa}.

\subsection{Features}

This DW project life cycle is based on four basic principles:

\begin{itemize}	
	
	\item Focus on the business: Concentrate on identifying business requirements and their associated
	value, and use these efforts to develop strong relationships with the business, sharpening the business
	analysis and consultative competence of the implementers\cite{mdawa}.
	\item Build an adequate information infrastructure: Design a single, integrated, easy-to-use, high-performance
	information base that will reflect the wide range of business requirements identified in the company\cite{mdawa}.
	\item Deliver in significant increments: create the data warehouse (DW) in deliverable increments in
	6 to 12 month timeframes. Use the business value of each identified element to determine the order of
	application of the increments. In this the methodology resembles agile software construction methodologies\cite{mdawa}.
	\item Deliver the complete solution: provide all the elements necessary to deliver value to business users.
	To begin with, this means having a robust, well-designed, quality-tested, and accessible data warehouse.
	You must also provide ad hoc query tools, advanced reporting and analysis applications, training, support
	training, support, support, website and documentation\cite{mdawa}.
	
\end{itemize}

\subsection{Data Lake}

Existing reviews on data lake architectures commonly distinguish pond and zone Architectures.

\subsection{Pond Architecture}

Inmon designs a data lake as a set of data ponds\cite{Inmon}. A data pond can be viewed as a subdivision of a data lake
dealing with data of a specific type. According to Dixon’s specifications, each data pond is associated with a
specialized storage system, some specific data processing and conditioning (i.e., data transformation/preparation)
and a relevant analysis service.

\begin{center}
	\includegraphics[width=7cm]{./images/pondDL}
\end{center}

\subsection{Zone Architecture}

zone architectures assign data to a zone according to their degree of refinement\cite{Giebler}. For instance, Zaloni’s data
lake\cite{LaPlante} adopts a six-zone architecture.

\begin{center}
	\includegraphics[width=7cm]{./images/zoneDL}
\end{center}

\begin{itemize}	
	
	\item The transient loading zone deals with data under ingestion. Here, basic data quality checks are performed.
	\item The raw data zone handles data in near raw format coming from the transient zone.
	\item The trusted zone is where data are transferred once standardized and cleansed.
	\item From the trusted area, data move into the discovery sandbox where they can be accessed by data
	scientists through data wrangling or data discovery operations.
	\item On top of the discovery sandbox, the consumption zone allows business users to run “what if” scenarios
	through dashboard tools.
	\item The governance zone finally allows to manage, monitor and govern metadata, data quality, a
	data catalog and security.
	
\end{itemize}

\subsection{Comparative}

\begin{center}
	\includegraphics[width=7cm]{./images/comparative}
\end{center}

In Data Warehouse methodologies, data is organized, defined and metadata is applied to it before it is written and stored.
This process is known as "schema writing".
Whereas Data Lake consumes everything, including data types that are considered inappropriate for DW. Data is stored
in unprocessed form; information is stored in the schema as the data is extracted from the data source, not as it is written
to storage. This process is known as "schema read".

%----------------------------------------------------------------------------------------
%	Conclusions
%----------------------------------------------------------------------------------------

\section{Conclusions}
When choosing a methodology to develop a data warehouse, do not use methodologies that require extensive requirements
gathering and analysis phases, monolithic development phases that take too much time and very long deployment phases.
The objective of each developer should be to deliver a first implementation that satisfies a part of the needs, to demonstrate
the advantages of the data warehouse and to motivate the users, that is why you should choose a methodology that
meets these requirements, because the work should always be aimed at improving the quality and acceptance of the
same by the users who benefit.

%----------------------------------------------------------------------------------------
%	References
%----------------------------------------------------------------------------------------

\bibliographystyle{plain} 
\bibliography{references} 
\end{document}